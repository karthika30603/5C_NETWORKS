{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0fzlfE2LGWI",
        "outputId": "a570c8da-1b64-4f15-a304-292ded9b2db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/sample_data/Data.zip.ZIP, /content/sample_data/Data.zip.ZIP.zip or /content/sample_data/Data.zip.ZIP.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/sample_data/Data.zip.ZIP -d /content/sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phTwtXpw1GQc",
        "outputId": "4a44de64-3b64-40c4-feec-d2e3a194c661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpWAj0wS6Hzo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Apply CLAHE\n",
        "def apply_clahe(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    return clahe.apply(image)\n",
        "\n",
        "# Custom Dataset Class for 3D Brain MRI\n",
        "class Metastasis3DDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_filenames = []\n",
        "        self.mask_filenames = []\n",
        "\n",
        "        # Traverse through subdirectories and collect all .tif files\n",
        "        for root, _, files in os.walk(data_dir):\n",
        "            for f in files:\n",
        "                if f.endswith('.tif'):\n",
        "                    if '_mask' in f:  # Check if the file is a mask\n",
        "                        self.mask_filenames.append(os.path.join(root, f))\n",
        "                    else:  # Otherwise, it's an image\n",
        "                        self.image_filenames.append(os.path.join(root, f))\n",
        "\n",
        "        # Keep only the matched pairs\n",
        "        matched_images = set()\n",
        "        matched_masks = set()\n",
        "\n",
        "        for mask in self.mask_filenames:\n",
        "            mask_name = os.path.basename(mask).replace('_mask.tif', '.tif')\n",
        "            image_path = os.path.join(os.path.dirname(mask), mask_name)\n",
        "            if image_path in self.image_filenames:\n",
        "                matched_images.add(image_path)\n",
        "                matched_masks.add(mask)\n",
        "\n",
        "        self.image_filenames = list(matched_images)\n",
        "        self.mask_filenames = list(matched_masks)\n",
        "\n",
        "        # Ensure that the number of images and masks match\n",
        "        if len(self.image_filenames) != len(self.mask_filenames):\n",
        "            print(f\"Warning: {len(self.image_filenames)} images and {len(self.mask_filenames)} masks found.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_filenames[idx]\n",
        "        mask_path = self.mask_filenames[idx]  # Get the corresponding mask\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "        image = apply_clahe(image)  # Apply CLAHE\n",
        "\n",
        "        # Normalize the image\n",
        "        image = image / 255.0  # Normalize pixel values\n",
        "\n",
        "        # Load the mask\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "        mask = mask / 255.0  # Normalize mask pixel values\n",
        "\n",
        "        # Convert to a PIL Image for transformation\n",
        "        image = transforms.ToPILImage()(image)\n",
        "        mask = transforms.ToPILImage()(mask)\n",
        "\n",
        "        # Data Augmentation and Transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Define Data Augmentation and Normalization\n",
        "def get_transform(phase):\n",
        "    if phase == 'train':\n",
        "        return transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/drive/MyDrive/Data\"  # Update this to your actual data directory\n",
        "    train_dataset = Metastasis3DDataset(data_dir=data_dir, transform=get_transform('train'))\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    # Test DataLoader\n",
        "    for images, masks in train_loader:\n",
        "        print(images.shape, masks.shape)  # Verify the shape of the images and masks\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7gPmT9paHoI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Basic Convolution Block\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        return x\n",
        "\n",
        "# Up-sampling block for decoding path\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpBlock, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        self.conv = ConvBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat((x, skip), dim=1)  # Concatenate with the skip connection\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "# U-Net++ Architecture\n",
        "class NestedUNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=1):\n",
        "        super(NestedUNet, self).__init__()\n",
        "\n",
        "        # Encoder Path\n",
        "        self.conv1_0 = ConvBlock(in_channels, 64)\n",
        "        self.conv2_0 = ConvBlock(64, 128)\n",
        "        self.conv3_0 = ConvBlock(128, 256)\n",
        "        self.conv4_0 = ConvBlock(256, 512)\n",
        "        self.conv5_0 = ConvBlock(512, 1024)\n",
        "\n",
        "        # Decoder Path (with nested blocks)\n",
        "        self.up4_1 = UpBlock(1024, 512)\n",
        "        self.up3_2 = UpBlock(512, 256)\n",
        "        self.up2_3 = UpBlock(256, 128)\n",
        "        self.up1_4 = UpBlock(128, 64)\n",
        "\n",
        "        self.up3_1 = UpBlock(512, 256)\n",
        "        self.up2_2 = UpBlock(256, 128)\n",
        "        self.up1_3 = UpBlock(128, 64)\n",
        "\n",
        "        self.up2_1 = UpBlock(256, 128)\n",
        "        self.up1_2 = UpBlock(128, 64)\n",
        "\n",
        "        self.up1_1 = UpBlock(128, 64)\n",
        "\n",
        "        # Final Convolution: Adjust output channels according to num_classes\n",
        "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x1_0 = self.conv1_0(x)   # Encoder level 1\n",
        "        x2_0 = self.conv2_0(F.max_pool2d(x1_0, 2))  # Encoder level 2\n",
        "        x3_0 = self.conv3_0(F.max_pool2d(x2_0, 2))  # Encoder level 3\n",
        "        x4_0 = self.conv4_0(F.max_pool2d(x3_0, 2))  # Encoder level 4\n",
        "        x5_0 = self.conv5_0(F.max_pool2d(x4_0, 2))  # Encoder level 5\n",
        "\n",
        "        # Decoder with Nested Skip Connections\n",
        "        x4_1 = self.up4_1(x5_0, x4_0)  # First level decoding\n",
        "        x3_2 = self.up3_2(x4_1, x3_0)  # Second level decoding\n",
        "        x2_3 = self.up2_3(x3_2, x2_0)  # Third level decoding\n",
        "        x1_4 = self.up1_4(x2_3, x1_0)  # Fourth level decoding\n",
        "\n",
        "        x3_1 = self.up3_1(x4_0, x3_0)\n",
        "        x2_2 = self.up2_2(x3_1, x2_0)\n",
        "        x1_3 = self.up1_3(x2_2, x1_0)\n",
        "\n",
        "        x2_1 = self.up2_1(x3_0, x2_0)\n",
        "        x1_2 = self.up1_2(x2_1, x1_0)\n",
        "\n",
        "        x1_1 = self.up1_1(x2_0, x1_0)\n",
        "\n",
        "        # Output\n",
        "        output = self.final_conv(x1_4)  # Apply final 1x1 convolution to get segmentation mask\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg1L2_cCyhDc",
        "outputId": "4e10768d-8010-4b51-fd51-1d02cfbdba45"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1189/1189 [3:11:28<00:00,  9.66s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Loss: 0.4323, Dice Score: 0.6384\n",
            "Epoch [2/3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1189/1189 [2:56:03<00:00,  8.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/3], Loss: 0.4149, Dice Score: 0.6384\n",
            "Epoch [3/3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 338/1189 [50:27<1:58:57,  8.39s/it]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "# Loss Function: BCE + Dice\n",
        "def bce_dice_loss(outputs, masks):\n",
        "    bce_loss = nn.BCEWithLogitsLoss()(outputs, masks)\n",
        "    dice_loss = 1 - dice_coeff(outputs, masks)\n",
        "    return bce_loss + dice_loss\n",
        "\n",
        "# Dice Coefficient Calculation\n",
        "def dice_coeff(pred, target, smooth=1e-6):\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > 0.5).float()\n",
        "\n",
        "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
        "    union = pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3))\n",
        "\n",
        "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
        "    return dice.mean()\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, train_loader, optimizer, device, num_epochs=3):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_dice = 0.0\n",
        "        total_batches = len(train_loader)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            inputs, masks = batch\n",
        "            inputs, masks = inputs.to(device), masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = bce_dice_loss(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_dice += dice_coeff(outputs, masks).item()\n",
        "\n",
        "        avg_loss = epoch_loss / total_batches\n",
        "        avg_dice = epoch_dice / total_batches\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Dice Score: {avg_dice:.4f}\")\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    total_dice = 0.0\n",
        "    total_batches = len(val_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader):\n",
        "            inputs, masks = batch\n",
        "            inputs, masks = inputs.to(device), masks.to(device)\n",
        "            outputs = model(inputs)\n",
        "            total_dice += dice_coeff(outputs, masks).item()\n",
        "\n",
        "    avg_dice = total_dice / total_batches\n",
        "    print(f\"Validation Dice Score: {avg_dice:.4f}\")\n",
        "    return avg_dice\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/drive/MyDrive/Data\"  # Replace with your actual path\n",
        "\n",
        "    # Load dataset\n",
        "    full_dataset = Metastasis3DDataset(data_dir=data_dir, transform=get_transform('train'))\n",
        "\n",
        "    # Split into training and validation sets\n",
        "    train_size = int(0.8 * len(full_dataset))  # 80% for training\n",
        "    val_size = len(full_dataset) - train_size  # 20% for validation\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Model (assuming NestedUNet as your model)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = NestedUNet(in_channels=1).to(device)  # Instantiate your model with required arguments\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 3\n",
        "    train_model(model, train_loader, optimizer, device, num_epochs)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    evaluate_model(model, val_loader, device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}